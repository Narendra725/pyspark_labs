{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook will highlight comparison between Python and Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Path For Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_path_pd = \"/home/labuser/Downloads/orders.csv\"\n",
    "customers_path_pd = \"/home/labuser/Downloads/customers.csv\"\n",
    "restaurant_path_pd = \"/home/labuser/Downloads/restaurants.csv\"\n",
    "food_path_pd = \"/home/labuser/Downloads/food.csv\"\n",
    "orders_details_path_pd = \"/home/labuser/Downloads/orders_details.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Path for Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_path = \"file:///home/labuser/Downloads/orders.csv\"\n",
    "orders_details_path = \"file:///home/labuser/Downloads/orders_details.csv\"\n",
    "customers_path = \"file:///home/labuser/Downloads/customers.csv\"\n",
    "food_path = \"file:///home/labuser/Downloads/food.csv\"\n",
    "restaurant_path = \"file:///home/labuser/Downloads/restaurants.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FoodWagon is engaged in the task of data retrieval and analysis of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read the FoodWagon Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --> Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read orders and customers DataFrames\n",
    "orders_df_pd = pd.read_csv(orders_path_pd)\n",
    "customers_df_pd = pd.read_csv(customers_path_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  -->pyspark installation and importing it into the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SparkSession class from the pyspark.sql module\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-04 13:22:15,545 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Use the SparkSession to read the CSV file into a DataFrame called orders_df\n",
    "# - set the file format to \"csv\"\n",
    "# - set the \"header\" option to \"true\" to indicate that the first row of the CSV file contains column names\n",
    "# - set the \"inferSchema\" option to \"true\" to infer the schema of the DataFrame from the CSV file\n",
    "\n",
    "\n",
    "orders_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(orders_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q. Find orders with a restaurant_rating greater than 4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ids_orders</th>\n",
       "      <th>restaurant_ids_orders</th>\n",
       "      <th>restaurant_ratings</th>\n",
       "      <th>order_date</th>\n",
       "      <th>delivery_time</th>\n",
       "      <th>delivery_rating</th>\n",
       "      <th>partner_ids_orders</th>\n",
       "      <th>order_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000746314</td>\n",
       "      <td>193075</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>96.157046</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000108610</td>\n",
       "      <td>10000000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003950373</td>\n",
       "      <td>158013</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>40.521030</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000161663</td>\n",
       "      <td>10000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002362211</td>\n",
       "      <td>170560</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-09-04</td>\n",
       "      <td>39.526428</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000102688</td>\n",
       "      <td>10000000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004568851</td>\n",
       "      <td>187316</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>86.926029</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000102818</td>\n",
       "      <td>10000000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001843660</td>\n",
       "      <td>183296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>41.853198</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000027844</td>\n",
       "      <td>10000000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999993</th>\n",
       "      <td>1002574387</td>\n",
       "      <td>154295</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>100.892908</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000141009</td>\n",
       "      <td>10009999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999995</th>\n",
       "      <td>1001509362</td>\n",
       "      <td>190550</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2019-04-09</td>\n",
       "      <td>59.505508</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000126020</td>\n",
       "      <td>10009999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999997</th>\n",
       "      <td>1002140393</td>\n",
       "      <td>191333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-06-12</td>\n",
       "      <td>34.390790</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000147200</td>\n",
       "      <td>10009999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999998</th>\n",
       "      <td>1003343496</td>\n",
       "      <td>146043</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>60.699148</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000147737</td>\n",
       "      <td>10009999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999999</th>\n",
       "      <td>1002042204</td>\n",
       "      <td>130054</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-03-16</td>\n",
       "      <td>60.340709</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1000021054</td>\n",
       "      <td>10010000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8341021 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         customer_ids_orders  restaurant_ids_orders  restaurant_ratings  \\\n",
       "0                 1000746314                 193075                 5.0   \n",
       "1                 1003950373                 158013                 5.0   \n",
       "2                 1002362211                 170560                 5.0   \n",
       "3                 1004568851                 187316                 5.0   \n",
       "4                 1001843660                 183296                 5.0   \n",
       "...                      ...                    ...                 ...   \n",
       "9999993           1002574387                 154295                 5.0   \n",
       "9999995           1001509362                 190550                 4.7   \n",
       "9999997           1002140393                 191333                 5.0   \n",
       "9999998           1003343496                 146043                 5.0   \n",
       "9999999           1002042204                 130054                 5.0   \n",
       "\n",
       "         order_date  delivery_time  delivery_rating  partner_ids_orders  \\\n",
       "0        2019-09-30      96.157046              5.0          1000108610   \n",
       "1        2019-03-31      40.521030              5.0          1000161663   \n",
       "2        2022-09-04      39.526428              5.0          1000102688   \n",
       "3        2019-02-05      86.926029              5.0          1000102818   \n",
       "4        2019-06-22      41.853198              5.0          1000027844   \n",
       "...             ...            ...              ...                 ...   \n",
       "9999993  2021-03-02     100.892908              5.0          1000141009   \n",
       "9999995  2019-04-09      59.505508              5.0          1000126020   \n",
       "9999997  2020-06-12      34.390790              5.0          1000147200   \n",
       "9999998  2022-05-09      60.699148              5.0          1000147737   \n",
       "9999999  2022-03-16      60.340709              5.0          1000021054   \n",
       "\n",
       "            order_id  \n",
       "0        10000000001  \n",
       "1        10000000002  \n",
       "2        10000000003  \n",
       "3        10000000004  \n",
       "4        10000000005  \n",
       "...              ...  \n",
       "9999993  10009999994  \n",
       "9999995  10009999996  \n",
       "9999997  10009999998  \n",
       "9999998  10009999999  \n",
       "9999999  10010000000  \n",
       "\n",
       "[8341021 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter orders with restaurant_rating greater than 4.5\n",
    "high_rated_orders = orders_df_pd[orders_df_pd[\"restaurant_ratings\"] > 4.5]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "high_rated_orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------------+------------------+----------+------------------+---------------+------------------+-----------+\n",
      "|customer_ids_orders|restaurant_ids_orders|restaurant_ratings|order_date|     delivery_time|delivery_rating|partner_ids_orders|   order_id|\n",
      "+-------------------+---------------------+------------------+----------+------------------+---------------+------------------+-----------+\n",
      "|         1000746314|               193075|               5.0|2019-09-30| 96.15704575574165|            5.0|        1000108610|10000000001|\n",
      "|         1003950373|               158013|               5.0|2019-03-31| 40.52103039895692|            5.0|        1000161663|10000000002|\n",
      "|         1002362211|               170560|               5.0|2022-09-04|39.526427646585674|            5.0|        1000102688|10000000003|\n",
      "|         1004568851|               187316|               5.0|2019-02-05|   86.926029233531|            5.0|        1000102818|10000000004|\n",
      "|         1001843660|               183296|               5.0|2019-06-22|41.853197852842015|            5.0|        1000027844|10000000005|\n",
      "|         1001915126|               178862|               5.0|2020-02-11| 93.04790511212178|            5.0|        1000035013|10000000006|\n",
      "|         1001609805|               187185|               5.0|2022-01-31|48.134918018031705|            5.0|        1000133611|10000000008|\n",
      "|         1000042054|               156081|               5.0|2020-10-14|  72.6670051868131|            5.0|        1000000578|10000000009|\n",
      "|         1002993415|               186531|               5.0|2019-12-19| 51.78126160368146|            5.0|        1000029064|10000000010|\n",
      "|         1003663133|               149005|               5.0|2021-12-18|113.35376724749685|            5.0|        1000144433|10000000011|\n",
      "|         1001175357|               130367|               5.0|2022-07-25| 73.76670330751142|            5.0|        1000129408|10000000012|\n",
      "|         1000126617|               201532|               5.0|2022-04-25|44.902957084763514|            5.0|        1000048360|10000000013|\n",
      "|         1001766256|               156458|               5.0|2022-05-31| 47.99011060675876|            5.0|        1000157742|10000000014|\n",
      "|         1001208065|               183293|               5.0|2021-12-10| 39.91967196950954|            5.0|        1000131557|10000000015|\n",
      "|         1002760221|               212790|               5.0|2021-07-28| 59.14292167367117|            5.0|        1000016874|10000000016|\n",
      "|         1000682966|               203433|               5.0|2019-02-13|48.512790266147796|            5.0|        1000007603|10000000018|\n",
      "|         1002957198|               166501|               5.0|2019-02-16| 68.71028077213425|            5.0|        1000099404|10000000019|\n",
      "|         1001112438|               156453|               5.0|2018-03-06|  59.1794408524095|            5.0|        1000046511|10000000020|\n",
      "|         1002441156|               162221|               5.0|2019-12-10|49.907765000446176|            5.0|        1000157356|10000000021|\n",
      "|         1002332155|               114557|               5.0|2018-03-23| 83.09783354161789|            5.0|        1000138455|10000000022|\n",
      "+-------------------+---------------------+------------------+----------+------------------+---------------+------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter orders with restaurant_rating greater than 4.5\n",
    "high_rated_orders = orders_df.filter(orders_df[\"restaurant_ratings\"] > 4.5)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "high_rated_orders.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. FoodWagon is offering a 10% discount on all food items and the The sales team wants to analyze the impact of this discount on the prices of food items. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df_pd = pd.read_csv(food_path_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_menu</th>\n",
       "      <th>food_name</th>\n",
       "      <th>food_price</th>\n",
       "      <th>discounted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Burger</td>\n",
       "      <td>Aloo Tikki Burger</td>\n",
       "      <td>40</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Burger</td>\n",
       "      <td>Veg Creamy Burger</td>\n",
       "      <td>50</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burger</td>\n",
       "      <td>Cheese Burst Burger</td>\n",
       "      <td>65</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burger</td>\n",
       "      <td>Paneer Creamy Burger</td>\n",
       "      <td>80</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Burger</td>\n",
       "      <td>Maxican Burger</td>\n",
       "      <td>80</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951734</th>\n",
       "      <td>Fresh Base Pizza</td>\n",
       "      <td>7''cheese &amp; Paneer Pizza</td>\n",
       "      <td>185</td>\n",
       "      <td>166.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951735</th>\n",
       "      <td>Fresh Base Pizza</td>\n",
       "      <td>7''fresh Farm Pizza</td>\n",
       "      <td>210</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951736</th>\n",
       "      <td>Fresh Base Pizza</td>\n",
       "      <td>7''paneer &amp; Onion Pizza</td>\n",
       "      <td>199</td>\n",
       "      <td>179.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951737</th>\n",
       "      <td>Fresh Base Pizza</td>\n",
       "      <td>7''veggie Delight Pizza</td>\n",
       "      <td>260</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951738</th>\n",
       "      <td>Fresh Base Pizza</td>\n",
       "      <td>7''paneer Paradise Pizza</td>\n",
       "      <td>290</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2951739 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                food_menu                 food_name  food_price  \\\n",
       "0                  Burger         Aloo Tikki Burger          40   \n",
       "1                  Burger         Veg Creamy Burger          50   \n",
       "2                  Burger       Cheese Burst Burger          65   \n",
       "3                  Burger      Paneer Creamy Burger          80   \n",
       "4                  Burger            Maxican Burger          80   \n",
       "...                   ...                       ...         ...   \n",
       "2951734  Fresh Base Pizza  7''cheese & Paneer Pizza         185   \n",
       "2951735  Fresh Base Pizza       7''fresh Farm Pizza         210   \n",
       "2951736  Fresh Base Pizza   7''paneer & Onion Pizza         199   \n",
       "2951737  Fresh Base Pizza   7''veggie Delight Pizza         260   \n",
       "2951738  Fresh Base Pizza  7''paneer Paradise Pizza         290   \n",
       "\n",
       "         discounted_price  \n",
       "0                    36.0  \n",
       "1                    45.0  \n",
       "2                    58.5  \n",
       "3                    72.0  \n",
       "4                    72.0  \n",
       "...                   ...  \n",
       "2951734             166.5  \n",
       "2951735             189.0  \n",
       "2951736             179.1  \n",
       "2951737             234.0  \n",
       "2951738             261.0  \n",
       "\n",
       "[2951739 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column for discounted price (10% discount)\n",
    "food_df_pd[\"discounted_price\"] = food_df_pd[\"food_price\"] * 0.9\n",
    "\n",
    "# Display the food data with original and discounted prices\n",
    "food_df_pd[[\"food_menu\", \"food_name\", \"food_price\", \"discounted_price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "food_df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(food_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+----------+----------------+\n",
      "|        food_menu|           food_name|food_price|discounted_price|\n",
      "+-----------------+--------------------+----------+----------------+\n",
      "|           Burger|   Aloo Tikki Burger|        40|            36.0|\n",
      "|           Burger|   Veg Creamy Burger|        50|            45.0|\n",
      "|           Burger| Cheese Burst Burger|        65|            58.5|\n",
      "|           Burger|Paneer Creamy Burger|        80|            72.0|\n",
      "|           Burger|      Maxican Burger|        80|            72.0|\n",
      "|           Burger|  Bbq Chicken Burger|       105|            94.5|\n",
      "|           Burger|Peri Peri Chicken...|       105|            94.5|\n",
      "|   Pasta Must Try|         White Sauce|       100|            90.0|\n",
      "|   Pasta Must Try|           Red Sauce|       100|            90.0|\n",
      "|   Pasta Must Try|          Pink Sauce|       125|           112.5|\n",
      "|   Pasta Must Try|        Masala Pasta|       100|            90.0|\n",
      "|   Pasta Must Try|       Chicken Pasta|       125|           112.5|\n",
      "|   Pasta Must Try|           Egg Pasta|       125|           112.5|\n",
      "|Chiness Appetizer|             Noodles|        90|            81.0|\n",
      "|Chiness Appetizer|   Singapuri Noodles|       100|            90.0|\n",
      "|Chiness Appetizer|       Hakka Noodles|        90|            81.0|\n",
      "|Chiness Appetizer|      Garlic Noodles|       100|            90.0|\n",
      "|Chiness Appetizer|      Paneer Noodles|       120|           108.0|\n",
      "|Chiness Appetizer|      Dry Manchurian|       190|           171.0|\n",
      "|Chiness Appetizer|    Gravy Manchurian|       200|           180.0|\n",
      "+-----------------+--------------------+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a column for discounted price\n",
    "discounted_food_data = food_df.withColumn(\"discounted_price\", col(\"food_price\") * 0.9)\n",
    "\n",
    "# Display the original and discounted prices\n",
    "result = discounted_food_data.select(\"food_menu\", \"food_name\", \"food_price\", \"discounted_price\")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q. FoodWagon is optimizing its order details records and wants to improve column naming. The team decided to rename the \"food_qty\" column to \"food_quantity\" in the \"order_details\" data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_details_df_pd = pd.read_csv(orders_details_path_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_ids_detail</th>\n",
       "      <th>food_ids_detail</th>\n",
       "      <th>food_quantity</th>\n",
       "      <th>detail_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002966982</td>\n",
       "      <td>1002945683</td>\n",
       "      <td>2</td>\n",
       "      <td>10000000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001111117</td>\n",
       "      <td>1000876144</td>\n",
       "      <td>5</td>\n",
       "      <td>10000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10006755508</td>\n",
       "      <td>1000045611</td>\n",
       "      <td>2</td>\n",
       "      <td>10000000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001799109</td>\n",
       "      <td>1001827128</td>\n",
       "      <td>2</td>\n",
       "      <td>10000000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10006713375</td>\n",
       "      <td>1001514543</td>\n",
       "      <td>1</td>\n",
       "      <td>10000000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999994</th>\n",
       "      <td>10009825064</td>\n",
       "      <td>1001379137</td>\n",
       "      <td>2</td>\n",
       "      <td>10009999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999995</th>\n",
       "      <td>10005529493</td>\n",
       "      <td>1002873454</td>\n",
       "      <td>1</td>\n",
       "      <td>10009999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999996</th>\n",
       "      <td>10005981894</td>\n",
       "      <td>1002459514</td>\n",
       "      <td>1</td>\n",
       "      <td>10009999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999997</th>\n",
       "      <td>10001137401</td>\n",
       "      <td>1002834502</td>\n",
       "      <td>2</td>\n",
       "      <td>10009999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999998</th>\n",
       "      <td>10007262683</td>\n",
       "      <td>1000524205</td>\n",
       "      <td>1</td>\n",
       "      <td>10009999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9999999 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_ids_detail  food_ids_detail  food_quantity    detail_id\n",
       "0             10002966982       1002945683              2  10000000001\n",
       "1             10001111117       1000876144              5  10000000002\n",
       "2             10006755508       1000045611              2  10000000003\n",
       "3             10001799109       1001827128              2  10000000004\n",
       "4             10006713375       1001514543              1  10000000005\n",
       "...                   ...              ...            ...          ...\n",
       "9999994       10009825064       1001379137              2  10009999995\n",
       "9999995       10005529493       1002873454              1  10009999996\n",
       "9999996       10005981894       1002459514              1  10009999997\n",
       "9999997       10001137401       1002834502              2  10009999998\n",
       "9999998       10007262683       1000524205              1  10009999999\n",
       "\n",
       "[9999999 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the \"food_qty\" column to \"food_quantity\"\n",
    "orders_details_df_pd.rename(columns={\"food_qty\": \"food_quantity\"}, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "orders_details_df_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "orders_details_df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(orders_details_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+-------------+-----------+\n",
      "|order_ids_detail|food_ids_detail|food_quantity|  detail_id|\n",
      "+----------------+---------------+-------------+-----------+\n",
      "|     10002966982|     1002945683|            2|10000000001|\n",
      "|     10001111117|     1000876144|            5|10000000002|\n",
      "|     10006755508|     1000045611|            2|10000000003|\n",
      "|     10001799109|     1001827128|            2|10000000004|\n",
      "|     10006713375|     1001514543|            1|10000000005|\n",
      "|     10002120033|     1000355682|            1|10000000006|\n",
      "|     10000579611|     1002709653|            1|10000000007|\n",
      "|     10004412998|     1001462406|            1|10000000008|\n",
      "|     10009790293|     1002305816|            1|10000000009|\n",
      "|     10004582144|     1002904452|            4|10000000010|\n",
      "|     10001990806|     1001260796|            2|10000000011|\n",
      "|     10001614375|     1000850066|            2|10000000012|\n",
      "|     10005846269|     1000283204|            1|10000000013|\n",
      "|     10005217446|     1000902455|            3|10000000014|\n",
      "|     10005898159|     1001792084|            3|10000000015|\n",
      "|     10001060338|     1001913840|            2|10000000016|\n",
      "|     10002650522|     1002770823|            3|10000000017|\n",
      "|     10002971849|     1000830487|            3|10000000018|\n",
      "|     10000526967|     1000882903|            2|10000000019|\n",
      "|     10000939820|     1000934133|            2|10000000020|\n",
      "+----------------+---------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename the \"food_qty\" column to \"food_quantity\"\n",
    "renamed_order_details_data = orders_details_df.withColumnRenamed(\"food_qty\", \"food_quantity\")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "renamed_order_details_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. FoodWagon wants to drop the licension number field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants_df_pd = pd.read_csv(restaurant_path_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurant_city</th>\n",
       "      <th>restaurant_name</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>restaurant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abohar</td>\n",
       "      <td>AB FOODS POINT</td>\n",
       "      <td>Beverages and Pizzas</td>\n",
       "      <td>100001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abohar</td>\n",
       "      <td>Janta Sweet House</td>\n",
       "      <td>Sweets and Bakery</td>\n",
       "      <td>100002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abohar</td>\n",
       "      <td>theka coffee desi</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>100003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abohar</td>\n",
       "      <td>Singh Hut</td>\n",
       "      <td>Fast Food and Indian</td>\n",
       "      <td>100004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abohar</td>\n",
       "      <td>GRILL MASTERS</td>\n",
       "      <td>Italian-American and Fast Food</td>\n",
       "      <td>100005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120679</th>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>The Food Delight</td>\n",
       "      <td>Fast Food and Snacks</td>\n",
       "      <td>220680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120680</th>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>MAITRI FOODS &amp; BEVERAGES</td>\n",
       "      <td>Pizzas</td>\n",
       "      <td>220681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120681</th>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>Cafe Bella Ciao</td>\n",
       "      <td>Fast Food and Snacks</td>\n",
       "      <td>220682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120682</th>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>GRILL ZILLA</td>\n",
       "      <td>Continental</td>\n",
       "      <td>220683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120683</th>\n",
       "      <td>Yavatmal</td>\n",
       "      <td>Lazeez kitchen</td>\n",
       "      <td>Pizzas</td>\n",
       "      <td>220684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120684 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       restaurant_city           restaurant_name  \\\n",
       "0               Abohar            AB FOODS POINT   \n",
       "1               Abohar         Janta Sweet House   \n",
       "2               Abohar         theka coffee desi   \n",
       "3               Abohar                 Singh Hut   \n",
       "4               Abohar             GRILL MASTERS   \n",
       "...                ...                       ...   \n",
       "120679        Yavatmal          The Food Delight   \n",
       "120680        Yavatmal  MAITRI FOODS & BEVERAGES   \n",
       "120681        Yavatmal           Cafe Bella Ciao   \n",
       "120682        Yavatmal               GRILL ZILLA   \n",
       "120683        Yavatmal            Lazeez kitchen   \n",
       "\n",
       "                               cuisine  restaurant_id  \n",
       "0                 Beverages and Pizzas         100001  \n",
       "1                    Sweets and Bakery         100002  \n",
       "2                            Beverages         100003  \n",
       "3                 Fast Food and Indian         100004  \n",
       "4       Italian-American and Fast Food         100005  \n",
       "...                                ...            ...  \n",
       "120679            Fast Food and Snacks         220680  \n",
       "120680                          Pizzas         220681  \n",
       "120681            Fast Food and Snacks         220682  \n",
       "120682                     Continental         220683  \n",
       "120683                          Pizzas         220684  \n",
       "\n",
       "[120684 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the \"licension no\" column\n",
    "restaurants_df_pd.drop(columns=[\"licension no\"], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "restaurants_df_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(restaurant_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+--------------------+-------------+\n",
      "|restaurant_city|     restaurant_name|             cuisine|restaurant_id|\n",
      "+---------------+--------------------+--------------------+-------------+\n",
      "|         Abohar|      AB FOODS POINT|Beverages and Pizzas|       100001|\n",
      "|         Abohar|   Janta Sweet House|   Sweets and Bakery|       100002|\n",
      "|         Abohar|   theka coffee desi|           Beverages|       100003|\n",
      "|         Abohar|           Singh Hut|Fast Food and Indian|       100004|\n",
      "|         Abohar|       GRILL MASTERS|Italian-American ...|       100005|\n",
      "|         Abohar|           Sam Uncle|         Continental|       100006|\n",
      "|         Abohar|    shere punjab veg|        North Indian|       100007|\n",
      "|         Abohar|Shri Balaji Vaish...|        North Indian|       100008|\n",
      "|         Abohar|Hinglaj Kachori B...|    Snacks and Chaat|       100009|\n",
      "|         Abohar|           yummy hub|              Indian|       100010|\n",
      "|         Abohar|CHAWLA SAAB THE J...|Juices and Beverages|       100011|\n",
      "|         Abohar|    Sethi Milk Badam| Sweets and Desserts|       100012|\n",
      "|         Abohar|       Swastik Dhaba|        North Indian|       100013|\n",
      "|         Abohar|    Jodhpuri Kachori|              Snacks|       100014|\n",
      "|         Abohar|   Bharawan Da Dhaba|              Indian|       100015|\n",
      "|         Abohar|     Tandoori Nights|             Tandoor|       100016|\n",
      "|         Abohar|        Roll Express|           Fast Food|       100017|\n",
      "|         Abohar|wah ji waah veg a...|North Indian and ...|       100018|\n",
      "|         Abohar|Shri Balaji fast ...|              Indian|       100019|\n",
      "|         Abohar|          FOODY MOOD|Fast Food and Chi...|       100020|\n",
      "+---------------+--------------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop the \"licension no\" column\n",
    "restaurant_data = restaurants_df.drop(\"licension no\")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "restaurant_data.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. In pursuit of menu optimization, FoodWagon is currently scrutinizing the food menu, requiring distinct food_menu names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Burger', 'Pasta Must Try', 'Chiness Appetizer', ...,\n",
       "       'Tandoori Roti and Naan and Paratha', 'Flaoters',\n",
       "       'Bella Ciao Special'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique food_menu values\n",
    "unique_food_menus = food_df_pd[\"food_menu\"].unique()\n",
    "\n",
    "# Display the unique food_menu values\n",
    "unique_food_menus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 12:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|food_menu                     |\n",
      "+------------------------------+\n",
      "|Kidzee                        |\n",
      "|Fried Rice                    |\n",
      "|Fresh Fruit and Dry Fruit     |\n",
      "|All Day Feast                 |\n",
      "|Special Stuffing Dosa         |\n",
      "|Pickles                       |\n",
      "|Hyderabadi Biryani            |\n",
      "|Scratch Speciality            |\n",
      "|Platers                       |\n",
      "|Starter For Vegetarian        |\n",
      "|Italian Gelato (Low Fat)      |\n",
      "|Deserts & Drinks              |\n",
      "|Continental & Desserts        |\n",
      "|Flavours Curated by ITC Mughal|\n",
      "|Festive Box [Savings upto 15%]|\n",
      "|Special Veg Fried Items       |\n",
      "|Burger Singh                  |\n",
      "|Apperitzers / Starter         |\n",
      "|Veg Breakfast                 |\n",
      "|Hot Bevrage                   |\n",
      "+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get unique food_menu values\n",
    "unique_food_menus = food_df.select(\"food_menu\").distinct()\n",
    "\n",
    "# Show the unique food_menu values\n",
    "unique_food_menus.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. calculate the average delivery rating for each restaurant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "restaurant_ids_orders\n",
       "100001    5.0\n",
       "100002    5.0\n",
       "100003    5.0\n",
       "100004    5.0\n",
       "100005    5.0\n",
       "         ... \n",
       "220680    5.0\n",
       "220681    5.0\n",
       "220682    5.0\n",
       "220683    5.0\n",
       "220684    5.0\n",
       "Name: delivery_rating, Length: 120684, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group orders by restaurant and calculate the average delivery rating\n",
    "average_delivery_ratings = orders_df_pd.groupby(\"restaurant_ids_orders\")[\"delivery_rating\"].mean()\n",
    "\n",
    "# Display the average delivery ratings\n",
    "average_delivery_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 14:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+\n",
      "|restaurant_ids_orders|avg(delivery_rating)|\n",
      "+---------------------+--------------------+\n",
      "|               161234|                 5.0|\n",
      "|               197148|                 5.0|\n",
      "|               172959|   4.994871794871795|\n",
      "|               117994|  4.9975000000000005|\n",
      "|               185705|                 5.0|\n",
      "|               185506|   4.997402597402598|\n",
      "|               156749|   4.985714285714286|\n",
      "|               160767|                 5.0|\n",
      "|               204529|                 5.0|\n",
      "|               149177|                 5.0|\n",
      "|               165829|   4.993478260869565|\n",
      "|               131931|                 5.0|\n",
      "|               160820|                 5.0|\n",
      "|               154033|                 5.0|\n",
      "|               180753|                 5.0|\n",
      "|               216014|   4.992307692307692|\n",
      "|               147961|                 5.0|\n",
      "|               146224|                 5.0|\n",
      "|               206378|                 5.0|\n",
      "|               208595|                 5.0|\n",
      "+---------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 14:=======>                                                  (1 + 7) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Group orders by restaurant and calculate the average delivery rating\n",
    "average_delivery_ratings = orders_df.groupBy(\"restaurant_ids_orders\").agg({\"delivery_rating\": \"avg\"})\n",
    "\n",
    "# Show the average delivery ratings\n",
    "average_delivery_ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. FoodWagon wants to analyze the average delivery rating of orders for each cuisine type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuisine\n",
      "8:15 To 11:30 Pm                                                   4.999695\n",
      "Afghani                                                            4.999738\n",
      "Afghani and  Biryani and  Chinese and  Indian and  North Indian    5.000000\n",
      "Afghani and  Fast Food                                             5.000000\n",
      "Afghani and  North Indian and  Indian and  Beverages               5.000000\n",
      "                                                                     ...   \n",
      "Waffle and Chinese                                                 5.000000\n",
      "Waffle and Desserts                                                4.998671\n",
      "Waffle and Fast Food                                               5.000000\n",
      "Waffle and Ice Cream                                               4.996912\n",
      "Waffle and Snacks                                                  4.997664\n",
      "Name: delivery_rating, Length: 5428, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Perform the join operation\n",
    "joined_data = pd.merge(orders_df_pd, restaurants_df_pd, left_on=\"restaurant_ids_orders\", right_on=\"restaurant_id\")\n",
    "\n",
    "# Calculate the average delivery rating for each cuisine type\n",
    "avg_delivery_by_cuisine = joined_data.groupby(\"cuisine\")[\"delivery_rating\"].mean()\n",
    "\n",
    "# Display the resulting report\n",
    "print(avg_delivery_by_cuisine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 17:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|             cuisine|avg(delivery_rating)|\n",
      "+--------------------+--------------------+\n",
      "| Arabian and Chinese|  4.9979650032404415|\n",
      "|Fast Food and Indian|   4.998508146306353|\n",
      "|South Indian and ...|   4.998376982663224|\n",
      "|    Pizzas and Combo|   4.999290420679168|\n",
      "|North Indian and ...|  4.9990476190476185|\n",
      "|Arabian and  Indi...|   4.999408284023668|\n",
      "|Chinese and  Tand...|                 5.0|\n",
      "|Fast Food and Bur...|   4.999497319034852|\n",
      "|Lebanese and Fast...|   4.998317417007732|\n",
      "|American and Stre...|   4.994495412844037|\n",
      "| Ice Cream and Chaat|    4.99980732177264|\n",
      "|Beverages and  In...|   4.998677248677248|\n",
      "|Snacks and  Pizza...|                 5.0|\n",
      "|Snacks and  Desserts|                 5.0|\n",
      "|South Indian and ...|   4.999236641221374|\n",
      "|     Indian and Cafe|                 5.0|\n",
      "|Thalis and  Rajas...|   4.995945945945945|\n",
      "|   Snacks and Haleem|                 5.0|\n",
      "|Ice Cream and  It...|                 5.0|\n",
      "|Italian-American ...|                 5.0|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 17:=============================>                            (4 + 4) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Perform the join operation\n",
    "joined_data = orders_df.join(restaurant_data, orders_df[\"restaurant_ids_orders\"] == restaurant_data[\"restaurant_id\"])\n",
    "\n",
    "# Calculate the average delivery rating for each cuisine type\n",
    "avg_delivery_by_cuisine = joined_data.groupBy(\"cuisine\").agg({\"delivery_rating\": \"avg\"})\n",
    "\n",
    "# Show the resulting report\n",
    "avg_delivery_by_cuisine.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The sql function on a SparkSession enables applications to run SQL queries programmatically and returns the result as a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FoodWagon wants to run SQL queries on top of the Data. \n",
    "- Create dataframe\n",
    "- Create TempView on top of this Dataframe\n",
    "- Run SQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(restaurant_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In Spark, the createOrReplaceTempView method is used to create a temporary view from a DataFrame. A temporary view is a named table-like structure that allows you to execute SQL queries on DataFrame data using Spark's SQL API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants_df.createOrReplaceTempView(\"restaurant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-->Let's see all records from restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = spark.sql(\"SELECT * FROM restaurant\")\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  FoodWagon is identifying the partner restaurants that provide this particular cuisine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = spark.sql(\"\"\" SELECT * FROM restaurant where cuisine = 'Beverages and Pizzas' \"\"\")\n",
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FoodWagon is in the process of pinpointing the cities from the restaurant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df = spark.sql(\"\"\" SELECT restaurant_city, count(*) as city_count FROM restaurant \\\n",
    "                        group by restaurant_city \"\"\")\n",
    "aggregated_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is how FoodWagon can run SQL Query by creating TempView. But Temporary views in Spark SQL are session-scoped and will disappear if the session that creates it terminates \n",
    "- If you want to have a temporary view that is shared among all sessions and keep alive until the Spark application terminates, you can create a **Global Temporary View.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a global temporary view\n",
    "restaurants_df.createGlobalTempView(\"restaurant_glob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global temporary view is tied to a system preserved database `global_temp`\n",
    "spark.sql(\"SELECT * FROM global_temp.restaurant_glob\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
